{
  "cells": [
    {
      "cell_type": "code",
      "id": "WZ7BmojBca2LBIUFpb8mrxV0",
      "metadata": {
        "tags": [],
        "id": "WZ7BmojBca2LBIUFpb8mrxV0"
      },
      "source": [
        "# @title 1. Setup, Extract & Feature Engineering\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from PIL import Image\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "zip_path = '/content/final_data.zip'\n",
        "extract_path = '/content/dataset'\n",
        "data_dir = os.path.join(extract_path, 'final_data')\n",
        "\n",
        "# 1. CLEAN & EXTRACT\n",
        "if os.path.exists(extract_path):\n",
        "    shutil.rmtree(extract_path)\n",
        "\n",
        "print(f\"üìÇ Extracting {zip_path}...\")\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        if 'final_data' in os.listdir(extract_path):\n",
        "            data_dir = os.path.join(extract_path, 'final_data')\n",
        "        else:\n",
        "            data_dir = extract_path\n",
        "\n",
        "    print(f\"‚úÖ Data extracted to: {data_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "# 2. FEATURE ENGINEERING\n",
        "print(\"\\n‚öôÔ∏è Configuring Augmentation...\")\n",
        "\n",
        "# [HYPERPARAMETER] Augmentation Strength\n",
        "# We distort training images so the model learns to ignore lighting/orientation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Clean transform for Validation/Test (No distortion, just resize)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Data Selection & Splitting (80/10/10 Split)\n",
        "print(\"üìä Loading and Splitting Data...\")\n",
        "\n",
        "try:\n",
        "    # 1. Load Full Dataset\n",
        "    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
        "    total_count = len(full_dataset)\n",
        "\n",
        "    # 2. Calculate Sizes (80% / 10% / 10%)\n",
        "    # [HYPERPARAMETER] Split Ratio\n",
        "    train_size = int(0.8 * total_count)\n",
        "    val_size = int(0.1 * total_count)\n",
        "    test_size = total_count - train_size - val_size\n",
        "\n",
        "    # 3. Perform Random Split\n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size]\n",
        "    )\n",
        "\n",
        "    # 4. Apply \"Clean\" Transform to Val and Test\n",
        "    val_dataset.dataset.transform = val_transform\n",
        "    test_dataset.dataset.transform = val_transform\n",
        "\n",
        "    # 5. Create Loaders\n",
        "    # [HYPERPARAMETER] Batch Size (default 16)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    print(f\"‚úÖ Success! Total Images: {total_count}\")\n",
        "    print(f\" - Training Set:   {train_size} (80%)\")\n",
        "    print(f\" - Validation Set: {val_size} (10%) -> Used for Tuning\")\n",
        "    print(f\" - Test Set:       {test_size} (10%) -> Used for Final Metrics\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ],
      "metadata": {
        "id": "9dhPsJVg8Axg"
      },
      "id": "9dhPsJVg8Axg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Model Training (with Hyperparameters)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"üß† Initializing ResNet-50...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Freeze the \"Brain\" (Feature Extractor)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the \"Head\" (Classifier)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4), # [HYPERPARAMETER] Dropout Rate\n",
        "    nn.Linear(256, 2)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# [HYPERPARAMETER] Learning Rate\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# [HYPERPARAMETER] Epochs & Patience\n",
        "epochs = 15\n",
        "patience = 3\n",
        "\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "history = {'acc': [], 'loss': []}\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"\\nüöÄ Starting Training...\")\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Check accuracy on Validation Set (The \"Practice Quiz\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_acc = 100 * correct / total\n",
        "    history['acc'].append(epoch_acc)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Val Acc: {epoch_acc:.2f}%\")\n",
        "\n",
        "    # Save model if it's the best one so far\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"üî¥ Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "# Load the best model for the final test\n",
        "model.load_state_dict(best_model_wts)\n",
        "plt.plot(history['acc'], marker='o', color='green'); plt.title(\"Validation Accuracy\"); plt.show()"
      ],
      "metadata": {
        "id": "ga5WyzIw8W6C"
      },
      "id": "ga5WyzIw8W6C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Qualitative Analysis (Automatic from Test Set)\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"üì∏ Automatically selecting 8 random images from the Test Set (Unseen Data)...\")\n",
        "\n",
        "num_samples = 8\n",
        "# We pick random images from the Test Set\n",
        "random_indices = random.sample(range(len(test_dataset)), num_samples)\n",
        "\n",
        "cols = 4\n",
        "rows = math.ceil(num_samples / cols)\n",
        "plt.figure(figsize=(15, 4 * rows))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Get the image and the True Label from the dataset\n",
        "    original_idx = test_dataset.indices[idx]\n",
        "    image_path, label_idx = full_dataset.samples[original_idx]\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = val_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        confidence, predicted_class = torch.max(probs, 1)\n",
        "\n",
        "    classes = full_dataset.classes\n",
        "    prediction = classes[predicted_class.item()]\n",
        "    score = confidence.item() * 100\n",
        "    ground_truth = classes[label_idx] # This is how we know if it's correct!\n",
        "\n",
        "    ax = plt.subplot(rows, cols, i + 1)\n",
        "    ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Green title = Correct, Red title = Wrong\n",
        "    color = 'green' if prediction == ground_truth else 'red'\n",
        "    ax.set_title(f\"Pred: {prediction} ({score:.1f}%)\\nTrue: {ground_truth}\",\n",
        "                 color=color, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"‚úÖ This grid shows how the model performed on data it never saw during training.\")"
      ],
      "metadata": {
        "id": "tMH3MnzV8bGp"
      },
      "id": "tMH3MnzV8bGp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Final Test Evaluation (Metrics on Test Split)\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"üìä Running Final Exam on Test Set (10% Split)...\")\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_probs = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # IMPORTANT: We iterate over test_loader now!\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to('cpu').numpy()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels)\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "        y_probs.extend(probs[:, 0].cpu().numpy())\n",
        "\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "# 1. Classification Report\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL TEST REPORT (80/10/10 Split)\")\n",
        "print(\"=\"*50)\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# 2. Confusion Matrix & ROC\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Test Set Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "y_true_binary = [1 if x == 0 else 0 for x in y_true]\n",
        "fpr, tpr, _ = roc_curve(y_true_binary, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(fpr, tpr, color='orange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üèÜ Final Test AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "Did3OTLN8gFj"
      },
      "id": "Did3OTLN8gFj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Launch Gradio App (Manual Upload)\n",
        "!pip install gradio -q\n",
        "import gradio as gr\n",
        "\n",
        "def predict_user_image(image):\n",
        "    if image is None: return None\n",
        "    image_tensor = val_transform(image).unsqueeze(0).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
        "    # Return probability for both classes\n",
        "    return {full_dataset.classes[i]: float(probs[i]) for i in range(2)}\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict_user_image,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Your Tile Image\"),\n",
        "    outputs=gr.Label(num_top_classes=2, label=\"AI Assessment\"),\n",
        "    title=\"Wall/Floor Tile Defect Inspector\",\n",
        "    description=\"Drop a tile image here to check for defects manually.\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "im2MPzgQ8lig"
      },
      "id": "im2MPzgQ8lig",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "6098952y (Feb 25, 2026, 4:09:11‚ÄØPM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}